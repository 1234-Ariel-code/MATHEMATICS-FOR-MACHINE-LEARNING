{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1.  Instructions Gram-Schmidt process\n",
    "In this assignment you will write a function to perform the Gram-Schmidt procedure, which takes a list of vectors and forms an orthonormal basis from this set.\n",
    "As a corollary, the procedure allows us to determine the dimension of the space spanned by the basis vectors, which is equal to or less than the space which the vectors sit.\n",
    "\n",
    "### Matrices in Python\n",
    "Remember the structure for matrices in *numpy* is,\n",
    "```python\n",
    "A[0, 0]  A[0, 1]  A[0, 2]  A[0, 3]\n",
    "A[1, 0]  A[1, 1]  A[1, 2]  A[1, 3]\n",
    "A[2, 0]  A[2, 1]  A[2, 2]  A[2, 3]\n",
    "A[3, 0]  A[3, 1]  A[3, 2]  A[3, 3]\n",
    "```\n",
    "You can access the value of each element individually using,\n",
    "```python\n",
    "A[n, m]\n",
    "```\n",
    "You can also access a whole row at a time using,\n",
    "```python\n",
    "A[n]\n",
    "```\n",
    "\n",
    "You can select whole columns at a time.\n",
    "This can be done with,\n",
    "```python\n",
    "A[:, m]\n",
    "```\n",
    "which will select the m'th column (starting at zero).\n",
    "\n",
    "In this exercise, you will need to take the dot product between vectors. This can be done using the @ operator.\n",
    "To dot product vectors u and v, use the code,\n",
    "```python\n",
    "u @ v\n",
    "```\n",
    "\n",
    "All the code you should complete will be at the same level of indentation as the instruction comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "verySmallNumber = 1e-14 # That's 1×10⁻¹⁴ = 0.00000000000001\n",
    "\n",
    "\n",
    "def gsBasis(A) :\n",
    "    B = np.array(A, dtype=np.float_) # Make B as a copy of A, since we're going to alter it's values.\n",
    "    # Loop over all vectors, starting with zero, label them with i\n",
    "    for i in range(B.shape[1]) :\n",
    "        # Inside that loop, loop over all previous vectors, j, to subtract.\n",
    "        for j in range(i) :\n",
    "            # Complete the code to subtract the overlap with previous vectors.\n",
    "            # you'll need the current vector B[:, i] and a previous vector B[:, j]\n",
    "            B[:, i] = B[:,i] - B[:,i] @ B[:,j] * B[:,j] ## EDIT THIS\n",
    "        # Next insert code to do the normalisation test for B[:, i]\n",
    "        if la.norm(B[:, i]) > verySmallNumber :\n",
    "            B[:, i] =   B[:, i] / la.norm(B[:, i]) ## EDIT THIS\n",
    "        else :\n",
    "            B[:, i] = np.zeros_like(B[:, i])      \n",
    "            \n",
    "    # Finally, we return the result:\n",
    "    return B\n",
    "\n",
    "# This function uses the Gram-schmidt process to calculate the dimension\n",
    "# spanned by a list of vectors.\n",
    "# Since each vector is normalised to one, or is zero,\n",
    "# the sum of all the norms will be the dimension.\n",
    "def dimensions(A) :\n",
    "    return np.sum(la.norm(gsBasis(A), axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using numpy implementation, \n",
    "\n",
    "def gs(X):\n",
    "    Q, R = np.linalg.qr(X) # mode='complete')\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([[1,0,2,6],\n",
    "              [0,1,8,2],\n",
    "              [2,8,3,1],\n",
    "              [1,-6,2,3]], dtype=np.float_)\n",
    "\n",
    "\n",
    "M = np.array([[1,1,1],[1,1,0], [1,0,0]], dtype=np.float_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## So we have a big problem here, the python implemntation differs from \n",
    "## our implementation. Bonus point if you can figure out why.\n",
    "\n",
    "np.testing.assert_almost_equal(gsBasis(V), gsBasis(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solution:\n",
    "The problem here is about determinent of our final matrix. Actually the determinent of our own matrix is equal to 1 instead of -1 given by the determinent of the generated matrix of numpy.testing, since there are multiplying the entries by -1 . So we wil still have an error since the determinent are different (1 for us and -1 for numpy.testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23643312,  0.18771349,  0.22132104],\n",
       "       [ 0.15762208,  0.74769023, -0.64395812],\n",
       "       [ 0.15762208,  0.57790444,  0.72904263],\n",
       "       [ 0.94573249, -0.26786082, -0.06951101]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what happens for non-square matrices\n",
    "A = np.array([[3,2,3],\n",
    "              [2,5,-1],\n",
    "              [2,4,8],\n",
    "              [12,2,1]], dtype=np.float_)\n",
    "gsBasis(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23643312, -0.18771349, -0.22132104],\n",
       "       [-0.15762208, -0.74769023,  0.64395812],\n",
       "       [-0.15762208, -0.57790444, -0.72904263],\n",
       "       [-0.94573249,  0.26786082,  0.06951101]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93704257, -0.12700832, -0.32530002,  0.        ,  0.        ],\n",
       "       [ 0.31234752,  0.72140727,  0.61807005,  0.        ,  0.        ],\n",
       "       [ 0.15617376, -0.6807646 ,  0.71566005,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[6,2,1,7,5],\n",
    "              [2,8,5,-4,1],\n",
    "              [1,-6,3,2,8]], dtype=np.float_)\n",
    "gsBasis(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.70710678, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's see what happens when we have one vector that is a linear combination of the others.\n",
    "C = np.array([[1,0,2],\n",
    "              [0,1,-3],\n",
    "              [1,0,2]], dtype=np.float_)\n",
    "gsBasis(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Page Rank Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Describe the PageRank Algorithm as seen in the python notebook on Page_rank.ipynb and relate it with the use of eigne-values and eigen-vectors. \n",
    "\n",
    "Provide your answers here. \n",
    "\n",
    "1- Description of PageRank Algorithm:\n",
    "\n",
    "The PageRank algorithm outputs a probability distribution used to represent the likelihood that a person randomly clicking on links will arrive at any particular page. PageRank can be calculated for collections of documents of any size. It is assumed in several research papers that the distribution is evenly divided among all documents in the collection at the beginning of the computational process. The PageRank computations require several passes, called “iterations”, through the collection to adjust approximate PageRank values to more closely reflect the theoretical true value.\n",
    "\n",
    "2- PageRank creates a vector of ranks: one element for each page; it also creates a matrix of links: each link from one page to another puts a '1' in the appropriate cell of the matrix.\n",
    "\n",
    "Then, it takes that vector -- initially set to some default (though I don't know, and it doesn't terribly matter, how this default is set) -- and repeatedly applies the link matrix to it.\n",
    "\n",
    "The PageRank vector p corresponds to the eigenvector of a particular matrix A corresponding to eigenvalue 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "linear-algebra-machine-learning",
   "graded_item_id": "FNk8v",
   "launcher_item_id": "DdvVk"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
